1> OLAP OPERATION CODE
 mysql -u root -p
Enter password:
Welcome to the MariaDB monitor. Commands end with ; or \g.
Your MariaDB connection id is 31
Server version: 10.11.6-MariaDB-0+deb12u1 Debian 12
Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.
Type 'help;' or '\h' for help. Type '\c' to clear the current input
statement.
MariaDB [(none)]> show databases;
+--------------------+
| Database |
+--------------------+
| TEA150 |
| information_schema |
| mysql |
| performance_schema || sys |
+--------------------+
5 rows in set (0.006 sec)
MariaDB [(none)]> CREATE DATABASE ECommerceClothingStore;
Query OK, 1 row affected (0.002 sec)
MariaDB [(none)]> USE ECommerceClothingStore;
Database changed
MariaDB [ECommerceClothingStore]> CREATE TABLE Product (
 -> Product_id INT PRIMARY KEY,
 -> Brand_name VARCHAR(50),
 -> Product_name VARCHAR(50),
 -> Material VARCHAR(50),
 -> Quantity INT
 -> );
Query OK, 0 rows affected (0.093 sec)
MariaDB [ECommerceClothingStore]> CREATE TABLE Customer (
 -> Cust_id INT PRIMARY KEY,
 -> Cust_Name VARCHAR(50),
 -> Age INT,
 -> Gender VARCHAR(10),
 -> Contact_No VARCHAR(15)
 -> );
Query OK, 0 rows affected (0.088 sec)
MariaDB [ECommerceClothingStore]> CREATE TABLE Time (
 -> Time_key INT PRIMARY KEY,
 -> Date DATE,
 -> Month VARCHAR(20),
 -> Quarter VARCHAR(20),
 -> Year INT
 -> );
Query OK, 0 rows affected (0.053 sec)
MariaDB [ECommerceClothingStore]> CREATE TABLE Location (
 -> Location_id INT PRIMARY KEY,
 -> Location_type VARCHAR(50),
 -> City_name VARCHAR(50),
 -> State VARCHAR(50),
 -> Country VARCHAR(50),
 -> Pin_code VARCHAR(10)
 -> );
Query OK, 0 rows affected (0.055 sec)
MariaDB [ECommerceClothingStore]> CREATE TABLE Cloth_Sales_Fact (
 -> Sale_id INT PRIMARY KEY AUTO_INCREMENT,
 -> Product_id INT,
 -> Cust_id INT,
 -> Time_key INT,
 -> Location_id INT,
 -> Total_profit DECIMAL(10, 2),
 -> Most_sold_brand VARCHAR(50),
 -> Most_sold_Product VARCHAR(50),
 -> FOREIGN KEY (Product_id) REFERENCES Product(Product_id),
 -> FOREIGN KEY (Cust_id) REFERENCES Customer(Cust_id),
 -> FOREIGN KEY (Time_key) REFERENCES Time(Time_key),
 -> FOREIGN KEY (Location_id) REFERENCES Location(Location_id)
 -> );
Query OK, 0 rows affected (0.077 sec)
MariaDB [ECommerceClothingStore]> INSERT INTO Product (Product_id,
Brand_name, Product_name, Material, Quantity) VALUES
 -> (101, 'BrandA', 'T-Shirt', 'Cotton', 100),
 -> (102, 'BrandB', 'Jeans', 'Denim', 50),
 -> (103, 'BrandC', 'Jacket', 'Leather', 20),
 -> (104, 'BrandD', 'Skirt', 'Silk', 30),
 -> (105, 'BrandE', 'Shorts', 'Polyester', 40);
Query OK, 5 rows affected (0.012 sec)
Records: 5 Duplicates: 0 Warnings: 0
MariaDB [ECommerceClothingStore]> select * from Product;
+------------+------------+--------------+-----------+----------+
| Product_id | Brand_name | Product_name | Material | Quantity |
+------------+------------+--------------+-----------+----------+
| 101 | BrandA | T-Shirt | Cotton | 100 |
| 102 | BrandB | Jeans | Denim | 50 |
| 103 | BrandC | Jacket | Leather | 20 |
| 104 | BrandD | Skirt | Silk | 30 |
| 105 | BrandE | Shorts | Polyester | 40 |
+------------+------------+--------------+-----------+----------+
5 rows in set (0.001 sec)
MariaDB [ECommerceClothingStore]> INSERT INTO Customer (Cust_id,
Cust_Name, Age, Gender, Contact_No) VALUES
 -> (201, 'Virat Kohli', 35, 'Male', '1234567890'),
 -> (202, 'Sania Mirza', 36, 'Female', '2345678901'),
 -> (203, 'PV Sindhu', 29, 'Female', '3456789012'),
 -> (204, 'MS Dhoni', 42, 'Male', '4567890123'),
 -> (205, 'Sachin Tendulkar', 50, 'Male', '5678901234');
Query OK, 5 rows affected (0.012 sec)
Records: 5 Duplicates: 0 Warnings: 0
MariaDB [ECommerceClothingStore]> select * from Customer;
+---------+------------------+------+--------+------------+
| Cust_id | Cust_Name | Age | Gender | Contact_No |
+---------+------------------+------+--------+------------+
| 201 | Virat Kohli | 35 | Male | 1234567890 |
| 202 | Sania Mirza | 36 | Female | 2345678901 |
| 203 | PV Sindhu | 29 | Female | 3456789012 |
| 204 | MS Dhoni | 42 | Male | 4567890123 |
| 205 | Sachin Tendulkar | 50 | Male | 5678901234 |
+---------+------------------+------+--------+------------+
5 rows in set (0.005 sec)
MariaDB [ECommerceClothingStore]> INSERT INTO Time (Time_key, Date,
Month, Quarter, Year) VALUES
 -> (301, '2024-01-01', 'January', 'Q1', 2024),
 -> (302, '2024-02-01', 'February', 'Q1', 2024),
 -> (303, '2024-03-01', 'March', 'Q1', 2024),
 -> (304, '2024-04-01', 'April', 'Q2', 2024),
 -> (305, '2024-05-01', 'May', 'Q2', 2024);
Query OK, 5 rows affected (0.017 sec)
Records: 5 Duplicates: 0 Warnings: 0
MariaDB [ECommerceClothingStore]> select * from Time;
+----------+------------+----------+---------+------+
| Time_key | Date | Month | Quarter | Year |
+----------+------------+----------+---------+------+
| 301 | 2024-01-01 | January | Q1 | 2024 |
| 302 | 2024-02-01 | February | Q1 | 2024 |
| 303 | 2024-03-01 | March | Q1 | 2024 |
| 304 | 2024-04-01 | April | Q2 | 2024 |
| 305 | 2024-05-01 | May | Q2 | 2024 |
+----------+------------+----------+---------+------+
5 rows in set (0.001 sec)
MariaDB [ECommerceClothingStore]> INSERT INTO Location (Location_id,
Location_type, City_name, State, Country, Pin_code) VALUES
 -> (401, 'Warehouse', 'Mumbai', 'Maharashtra', 'India', '400001'),
 -> (402, 'Store', 'Tokyo', 'Tokyo Metropolis', 'Japan', '100-0001'),
 -> (403, 'Warehouse', 'Delhi', 'Delhi NCR', 'India', '110001'),
 -> (404, 'Store', 'Osaka', 'Kansai', 'Japan', '530-0001'),
 -> (405, 'Warehouse', 'New York', 'New York State', 'USA', '10001');
Query OK, 5 rows affected (0.018 sec)
Records: 5 Duplicates: 0 Warnings: 0
MariaDB [ECommerceClothingStore]> select * from Location;
+------------+-------------+-----------+----------------+--------+-------
--+
|Location_id |Location_type| City_name |State |Country
|Pin_code |
+------------+-------------+-----------+----------------+--------+-------
--+
| 401 |Warehouse | Mumbai |Maharashtra |India |400001
|
| 402 |Store | Tokyo |Tokyo Metropolis|Japan |100-
0001 |
| 403 |Warehouse | Delhi |Delhi NCR |India |110001
|
| 404 |Store | Osaka |Kansai |Japan |530-
0001 |
| 405 |Warehouse | New York |New York State |USA |10001
|
+------------+-------------+-----------+----------------+--------+-------
--+
5 rows in set (0.001 sec)
MariaDB [ECommerceClothingStore]> INSERT INTO Cloth_Sales_Fact
(Product_id, Cust_id, Time_key, Location_id, Total_profit,
Most_sold_brand, Most_sold_Product) VALUES
 -> (101, 201, 301, 401, 1000.00, 'BrandA', 'T-Shirt'),
 -> (102, 202, 302, 402, 500.00, 'BrandB', 'Jeans'),
 -> (103, 203, 303, 403, 700.00, 'BrandC', 'Jacket'),
 -> (104, 204, 304, 404, 300.00, 'BrandD', 'Skirt'),
 -> (105, 205, 305, 405, 400.00, 'BrandE', 'Shorts');
Query OK, 5 rows affected (0.017 sec)
Records: 5 Duplicates: 0 Warnings: 0
MariaDB [ECommerceClothingStore]> select * from Cloth_Sales_Fact;
+---------+------------+---------+----------+-------------+--------------
+-----------------+-------------------+
| Sale_id | Product_id | Cust_id | Time_key | Location_id | Total_profit
| Most_sold_brand | Most_sold_Product |
+---------+------------+---------+----------+-------------+--------------
+-----------------+-------------------+
| 1 | 101 | 201 | 301 | 401 | 1000.00
| BrandA | T-Shirt |
| 2 | 102 | 202 | 302 | 402 | 500.00
| BrandB | Jeans |
| 3 | 103 | 203 | 303 | 403 | 700.00
| BrandC | Jacket |
| 4 | 104 | 204 | 304 | 404 | 300.00
| BrandD | Skirt |
| 5 | 105 | 205 | 305 | 405 | 400.00
| BrandE | Shorts |
+---------+------------+---------+----------+-------------+--------------
+-----------------+-------------------+
5 rows in set (0.001 sec)
1. Rollup
Rollup aggregates data by progressively removing detail.For example, you
can aggregate sales data first by City_name, then by State, and finally
by Country.
MariaDB [ECommerceClothingStore]> SELECT
 -> L.Country,
 -> L.State,
 -> L.City_name,
 -> SUM(CSF.Total_profit) AS Total_Sales
 -> FROM
 -> Cloth_Sales_Fact CSF
 -> JOIN
 -> Location L ON CSF.Location_id = L.Location_id
 -> GROUP BY
 -> L.Country, L.State, L.City_name;
+---------+------------------+-----------+-------------+
| Country | State | City_name | Total_Sales |
+---------+------------------+-----------+-------------+
| India | Delhi NCR | Delhi | 700.00 |
| India | Maharashtra | Mumbai | 1000.00 |
| Japan | Kansai | Osaka | 300.00 |
| Japan | Tokyo Metropolis | Tokyo | 500.00 |
| USA | New York State | New York | 400.00 |
+---------+------------------+-----------+-------------+
5 rows in set (0.008 sec)
2. Drilldown
For drilldown, you simply group by more detailed levels. For example,
drilling down to the city level within a specific state.
MariaDB [ECommerceClothingStore]> SELECT
 -> L.State,
 -> L.City_name,
 -> SUM(CSF.Total_profit) AS Total_Sales
 -> FROM
 -> Cloth_Sales_Fact CSF
 -> JOIN
 -> Location L ON CSF.Location_id = L.Location_id
 -> WHERE
 -> L.Country = 'India'
 -> GROUP BY
 -> L.State, L.City_name;
+-------------+-----------+-------------+
| State | City_name | Total_Sales |
+-------------+-----------+-------------+
| Delhi NCR | Delhi | 700.00 |
| Maharashtra | Mumbai | 1000.00 |
+-------------+-----------+-------------+
2 rows in set (0.012 sec)
3. Slice
Slice operation remains the same, focusing on a specific time period,
product, etc.
MariaDB [ECommerceClothingStore]> SELECT
 -> P.Brand_name,
 -> P.Product_name,
 -> SUM(CSF.Total_profit) AS Total_Sales
 -> FROM
 -> Cloth_Sales_Fact CSF
 -> JOIN
 -> Product P ON CSF.Product_id = P.Product_id
 -> JOIN
 -> Time T ON CSF.Time_key = T.Time_key
 -> WHERE
 -> T.Month = 'February'
 -> GROUP BY
 -> P.Brand_name, P.Product_name;
+------------+--------------+-------------+
| Brand_name | Product_name | Total_Sales |
+------------+--------------+-------------+
| BrandB | Jeans | 500.00 |
+------------+--------------+-------------+
1 row in set (0.002 sec)
4. Dice
Dice operation also remains the same, where you filter based on multiple
dimensions.
MariaDB [ECommerceClothingStore]> SELECT
 -> P.Brand_name,
 -> P.Product_name,
 -> L.City_name,
 -> SUM(CSF.Total_profit) AS Total_Sales
 -> FROM
 -> Cloth_Sales_Fact CSF
 -> JOIN
 -> Product P ON CSF.Product_id = P.Product_id
 -> JOIN
 -> Time T ON CSF.Time_key = T.Time_key
 -> JOIN
 -> Location L ON CSF.Location_id = L.Location_id
 -> WHERE
 -> P.Product_name = 'Jeans' AND
 -> T.Month = 'February' AND
 -> L.City_name = 'Tokyo'
 -> GROUP BY
 -> P.Brand_name, P.Product_name, L.City_name;
+------------+--------------+-----------+-------------+
| Brand_name | Product_name | City_name | Total_Sales |
+------------+--------------+-----------+-------------+
| BrandB | Jeans | Tokyo | 500.00 |
+------------+--------------+-----------+-------------+
1 row in set (0.003 sec) 



2> SNOWFLAKE USING SQL TABLE 



3>FREQUENT ITEMSET

from itertools import combinations
from collections import defaultdict

# Function to count the support of 2-itemsets
def count_itemsets(transactions, itemsets):
    itemset_counts = defaultdict(int)
    for transaction in transactions:
        for itemset in itemsets:
            if set(itemset).issubset(transaction):
                itemset_counts[itemset] += 1
    return itemset_counts

# Function to find frequent 2-itemsets
def find_frequent_itemsets(transactions, min_support):
    # Extract all unique items
    unique_items = sorted({item for transaction in transactions for item in transaction})

    # Generate all 2-itemsets
    two_itemsets = list(combinations(unique_items, 2))

    # Count support for each 2-itemset
    itemset_counts = count_itemsets(transactions, two_itemsets)

    # Filter 2-itemsets by minimum support
    frequent_itemsets = {itemset: count for itemset, count in itemset_counts.items() if count >= min_support}

    return frequent_itemsets

# Example dataset (transactions)
transactions = [
    ['milk', 'bread', 'butter'],
    ['beer', 'bread', 'butter'],
    ['milk', 'beer', 'bread'],
    ['milk', 'beer', 'butter'],
    ['beer', 'bread']
]

# Minimum support count
min_support = 2

# Find and print frequent 2-itemsets
frequent_itemsets = find_frequent_itemsets(transactions, min_support)
print("Frequent 2-itemsets with minimum support count of", min_support)
for itemset, count in frequent_itemsets.items():
    print(f"{itemset}: {count}")


4> K-MEANS

import random

# Function to calculate the Euclidean distance between two points
def euclidean_distance(point1, point2):
    return abs(point1 - point2)

# Function to initialize k centroids randomly from the dataset
def initialize_centroids(data, k):
    return random.sample(data, k)

# Function to assign each point to the nearest centroid
def assign_clusters(data, centroids):
    clusters = {}
    for point in data:
        distances = [euclidean_distance(point, centroid) for centroid in centroids]
        closest_index = distances.index(min(distances))
        if closest_index not in clusters:
            clusters[closest_index] = []
        clusters[closest_index].append(point)
    return clusters

# Function to update centroids based on the mean of points in each cluster
def update_centroids(clusters):
    new_centroids = []
    for points in clusters.values():
        new_centroid = sum(points) / len(points)
        new_centroids.append(new_centroid)
    return new_centroids

# K-means function
def k_means_clustering(data, k, max_iterations=100):
    # Step 1: Initialize centroids
    centroids = initialize_centroids(data, k)
    
    for _ in range(max_iterations):
        # Step 2: Assign points to clusters
        clusters = assign_clusters(data, centroids)
        
        # Step 3: Update centroids
        new_centroids = update_centroids(clusters)
        
        # Check for convergence (if centroids do not change)
        if new_centroids == centroids:
            break
        
        centroids = new_centroids

    return clusters, centroids

# Example dataset (one-dimensional)
data = {1, 2, 4, 8, 20, 40}
data = list(data)  # Convert set to a list

# Set the number of clusters (k)
k = 2

# Apply K-Means clustering
clusters, centroids = k_means_clustering(data, k)

# Display the results
print("Cluster centroids:")
for i, centroid in enumerate(centroids):
    print(f"Centroid {i + 1}: {centroid}")

print("\nClusters:")
for i, cluster_points in clusters.items():
    print(f"Cluster {i + 1}: {cluster_points}")
